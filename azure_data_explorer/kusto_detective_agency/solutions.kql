// Challenge 1
Onboarding
| summarize  total_score = sum(Score)
| project total_score



//////////////////////////////////////////////////////////
// Challenge 2

// Check how much the missing book weighs - 1764
Books
| where (book_title == "De Revolutionibus Magnis Data")
| project rf_id, weight_gram

// Calculate the difference between the weight of each shelf and how much it currently weighs
// The shelf with largest difference will be the one the book belongs to
// According to the exercise there is a small margin of error between real weight and measurements so the difference is rarely zero
Shelves 
| mv-expand rf_id = rf_ids to typeof(string) 
| lookup Books on rf_id 
| summarize total_weight = avg(total_weight), current_weight = sum(weight_gram) by shelf = shelf 
| extend weight_difference = total_weight - current_weight
| order by weight_difference desc 
| project shelf, total_weight, current_weight, weight_difference


//////////////////////////////////////////////////////////
// Challenge 3

// let multipleVoters =
// Votes
// | summarize c = count() by voter_hash_id
// | where c > 1
// | project voter_hash_id;
Votes
// | where not(voter_hash_id in (multipleVoters))
// Lots of votes for same candidate from a single machine in less than a minute, so aggegate machine votes at the minute granularity
| extend dt = format_datetime(Timestamp, "yyyy-MM-dd HH:mm")
| summarize c = count() by via_ip, vote, dt
// And keep only the credible votes (filters out e.g. 200+ votes for one candidate in a single machine for a one minute period)
| where c < 50
// Sum votes because they are already aggegated by ip and candidate
| summarize Count = sum(c) by vote
// Rest is provided code by exercise
| as hint.materialized=true T
| extend Total = toscalar(T | summarize sum(Count))
| project vote, Percentage = round(Count*100.0 / Total, 1), Count
| order by Count



//////////////////////////////////////////////////////////
// Challenge 4
.execute database script <|
// Create the table with the traffic information.
// The data loading process estimated to take ~3-4min to complete (114M+ rows of data).
// Notes: VIN - is Vehicle ID 
.create-merge table Traffic (Timestamp:datetime, VIN:string, Ave:int, Street:int)
.ingest async into table Traffic (@'https://kustodetectiveagency.blob.core.windows.net/digitown-traffic/log_00000.csv.gz')
.ingest async into table Traffic (@'https://kustodetectiveagency.blob.core.windows.net/digitown-traffic/log_00001.csv.gz')
.ingest async into table Traffic (@'https://kustodetectiveagency.blob.core.windows.net/digitown-traffic/log_00002.csv.gz')


// Cars that passed by the bank
let passedByBank =
Traffic
| where Ave == 157 and Street == 148
| distinct VIN
;
// Cars moving during the robbery
let movingDuringRobbery =
Traffic
| where 
    Timestamp >= datetime('2022-10-16T08:17:00Z')
    and Timestamp < datetime('2022-10-16T08:32:00Z')
| distinct VIN
;
// Cars stopped during the robbery
let stoppedDuringRobbery =
Traffic
| distinct VIN
| where not(VIN in (movingDuringRobbery))
;
Traffic
| where VIN in (stoppedDuringRobbery) and VIN in (passedByBank)
| summarize arg_max(Timestamp, *) by VIN
| summarize c = count() by Ave, Street
| where c == 3